import OpenAI from "openai";
import * as dotenv from "dotenv";
import { getHistory, appendHistory, Message } from "./conversationMemory";
import { ChatCompletionMessageParam } from "openai/resources/chat";
import { getChatbotById } from "../services/chatbotService";
import { getPrompt } from "../services/promptService";

dotenv.config();

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

export async function generateEmbeddings(text: string): Promise<number[]> {
  try {
    console.log("üìå Generando embeddings...");
    const response = await openai.embeddings.create({
      model: process.env.OPENAI_EMBEDDING_MODEL!,
      input: text,
    });
    return response.data[0].embedding;
  } catch (error) {
    console.error("‚ùå Error generando embeddings:", error);
    throw new Error("Error generando embeddings.");
  }
}

export async function generateResponse(
  userQuery: string,
  context: string = "",
  sessionId: string = "default",
  chatbotId: string
): Promise<string> {
  try {
    console.log("üì• Generando respuesta para chatbot:", chatbotId);

    // üß† Obtener el prompt del chatbot desde Azure Blob
    const prompt = await getPrompt(chatbotId);
    if (!prompt) {
      console.warn(`‚ö†Ô∏è Prompt no encontrado para chatbotId=${chatbotId}, usando valor por defecto.`);
    }

    // ‚öôÔ∏è Obtener configuraci√≥n del chatbot desde Azure Table Storage
    const chatbotConfig = await getChatbotById(chatbotId);
    if (!chatbotConfig) {
      console.error(`‚ùå Chatbot no encontrado en Table Storage: ${chatbotId}`);
      return "No se encontr√≥ la configuraci√≥n del chatbot solicitado.";
    }

    // üìö Contexto procesado
    const cleanContext = context.trim().length > 0
      ? `Aqu√≠ tienes la informaci√≥n disponible:\n\n${context}`
      : "No se encontraron datos relevantes para responder esta consulta.";

    // üìú Historial de conversaci√≥n
    const history: Message[] = getHistory(sessionId);
    const historyMessages: ChatCompletionMessageParam[] = history.map(m => ({
      role: m.role,
      content: m.content,
    }));

    // üß† Armar mensajes para OpenAI
    const messages: ChatCompletionMessageParam[] = [
      { role: "system", content: prompt || "Eres un asistente virtual de UTEC." },
      { role: "system", content: cleanContext },
      ...historyMessages,
      { role: "user", content: userQuery }
    ];

    // üß™ Enviar a OpenAI
    const response = await openai.chat.completions.create({
      model: chatbotConfig.model || "gpt-4",
      messages,
      max_tokens: chatbotConfig.maxTokens || 500,
      temperature: chatbotConfig.temperature ?? 0.5,
    });

    const reply = response.choices[0]?.message?.content || "No tengo informaci√≥n suficiente.";

    // üíæ Guardar en historial
    appendHistory(sessionId, { role: "user", content: userQuery });
    appendHistory(sessionId, { role: "assistant", content: reply });

    return reply;
  } catch (error) {
    console.error("‚ùå Error generando respuesta con OpenAI:", error);
    return "Hubo un error generando la respuesta.";
  }
}

// Este archivo manejar√° la l√≥gica para interactuar con la API de OpenAI, como la creaci√≥n de embeddings y generaci√≥n de respuestas.

import OpenAI from "openai";
import * as dotenv from "dotenv";

dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

// ‚úÖ Funci√≥n para generar embeddings con OpenAI
async function generateEmbeddings(text: string): Promise<number[]> {
  try {
    console.log("üìå Generando embeddings para:", text);
    const response = await openai.embeddings.create({
      model: process.env.OPENAI_EMBEDDING_MODEL!,
      input: text,
    });

    return response.data[0].embedding;
  } catch (error) {
    console.error("‚ùå Error generando embeddings:", error);
    throw new Error("Error generando embeddings");
  }
}

// ‚úÖ Funci√≥n para generar respuestas con OpenAI
async function generateResponse(userQuery: string, context: string = ""): Promise<string> {
  try {
    console.log("üìå Contexto proporcionado a OpenAI:", context);

    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: context
            ? `Eres un asistente que responde preguntas basadas en el siguiente contenido: ${context}.
               Si no encuentras informaci√≥n en el contenido, responde "No tengo informaci√≥n suficiente".`
            : "Eres un asistente de IA experto en responder preguntas.",
        },
        {
          role: "user",
          content: userQuery,
        },
      ],
      max_tokens: 200,
      temperature: 0.5,
    });

    return response.choices[0]?.message?.content || "No tengo informaci√≥n suficiente.";
  } catch (error) {
    console.error("‚ùå Error generando respuesta con OpenAI:", error);
    return "Hubo un error generando la respuesta.";
  }
}

export { generateEmbeddings, generateResponse };
